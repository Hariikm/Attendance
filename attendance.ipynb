{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured and saved .\\people\\Medini_C\\Medini_C_1.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_2.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_3.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_4.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_5.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_6.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_7.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_8.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_9.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_10.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_11.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_12.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_13.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_14.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_15.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_16.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_17.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_18.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_19.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_20.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_21.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_22.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_23.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_24.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_25.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_26.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_27.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_28.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_29.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_30.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_31.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_32.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_33.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_34.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_35.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_36.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_37.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_38.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_39.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_40.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_41.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_42.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_43.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_44.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_45.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_46.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_47.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_48.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_49.jpg\n",
      "Captured and saved .\\people\\Medini_C\\Medini_C_50.jpg\n",
      " All photos have been captured\n"
     ]
    }
   ],
   "source": [
    "# while capture_count < num_photos:\n",
    "num_photos = 50\n",
    "capture_count = 0\n",
    "face_encodings = []\n",
    "face_histograms = []\n",
    "person_name = input(\"Enter the name of the person: \")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while capture_count < num_photos:\n",
    "    ret, frame = cap.read()\n",
    "    # Convert frame to RGB for face recognition\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "    for face_encoding, face_location in zip(encodings, face_locations):\n",
    "        # Save the encoding\n",
    "        face_encodings.append(face_encoding)\n",
    "\n",
    "        # Calculate histogram for the face\n",
    "        top, right, bottom, left = face_location\n",
    "        face_roi = rgb_frame[top:bottom, left:right]\n",
    "        hist = cv2.calcHist([face_roi], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "        cv2.normalize(hist, hist)\n",
    "        face_histograms.append(hist)\n",
    "\n",
    "        # Creating a new directory for each person\n",
    "        face_dir= os.path.join(r'.\\people', f\"{person_name}\")\n",
    "\n",
    "        # Save the image to the specified folder\n",
    "        if not os.path.exists(face_dir):\n",
    "            os.makedirs(face_dir)\n",
    "\n",
    "        img_path = os.path.join(face_dir, f\"{person_name}_{capture_count + 1}.jpg\")\n",
    "        cv2.imwrite(img_path, frame)\n",
    "        print(f\"Captured and saved {img_path}\")\n",
    "\n",
    "        capture_count += 1\n",
    "\n",
    "        cv2.imshow(\"Camera Feed\", frame)\n",
    "\n",
    "        # Stop capturing after reaching the required number of photos\n",
    "        if capture_count >= num_photos:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "    # Press 'q' to quit early if needed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "print(\" All photos have been captured\")\n",
    "\n",
    "if not os.path.exists(\"encoding_dir\"):\n",
    "    os.mkdir(\"encoding_dir\")\n",
    "\n",
    "with open(f\"encoding_dir/face_encodings_{person_name}.pkl\", \"wb\") as f:\n",
    "    # Create a dictionary to store encodings and histograms\n",
    "    data_to_save = {}\n",
    "    for i, encoding in enumerate(face_encodings):\n",
    "        data_to_save[person_name] = {\n",
    "            'encoding': encoding,\n",
    "            'hist': face_histograms[i]\n",
    "        }\n",
    "    pickle.dump(data_to_save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face encodings saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Directory where images are stored\n",
    "image_directory = 'people'\n",
    "face_encodings = {}\n",
    "\n",
    "# Loop through each person in the image directory\n",
    "for person_name in os.listdir(image_directory):\n",
    "    person_dir = os.path.join(image_directory, person_name)\n",
    "    if os.path.isdir(person_dir):\n",
    "        all_encodings = []\n",
    "\n",
    "        for image_file in os.listdir(person_dir):\n",
    "            image_path = os.path.join(person_dir, image_file)\n",
    "\n",
    "            # Load image\n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "\n",
    "            # Get face encodings\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "            if encodings:\n",
    "                all_encodings.append(encodings[0])\n",
    "\n",
    "        # Average the encodings for this person\n",
    "        if all_encodings:\n",
    "            average_encoding = sum(all_encodings) / len(all_encodings)\n",
    "            face_encodings[person_name] = average_encoding\n",
    "\n",
    "# Save to a file\n",
    "with open(\"avg_encoding_dir/avg_face_encodings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(face_encodings, f)\n",
    "\n",
    "print(\"Face encodings saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"avg_encoding_dir/avg_face_encodings.pkl\", \"rb\") as f:\n",
    "    content= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9762\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.getsize(\"avg_encoding_dir/avg_face_encodings.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to quit or wait 5 seconds for automatic attendance.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import face_recognition\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "# Load face encodings\n",
    "with open(\"avg_encoding_dir/avg_face_encodings.pkl\", \"rb\") as f:\n",
    "    known_faces = pickle.load(f)\n",
    "\n",
    "print(\"Press 'q' to quit or wait 5 seconds for automatic attendance.\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "start_time = time.time()\n",
    "attendance_registered = False\n",
    "\n",
    "while True:\n",
    "    # Capture frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Convert frame to RGB for face recognition\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "    for (face_location, face_encoding) in zip(face_locations, face_encodings):\n",
    "        matches = face_recognition.compare_faces(list(known_faces.values()), face_encoding, tolerance=0.6)\n",
    "        \n",
    "        name = \"Unknown\"\n",
    "\n",
    "        if True in matches:\n",
    "            first_match_index = matches.index(True)\n",
    "            name = list(known_faces.keys())[first_match_index]\n",
    "\n",
    "            # # If a known person is detected and attendance is not yet registered\n",
    "            # if not attendance_registered:\n",
    "            #     # Get current time\n",
    "            #     current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "            #     # Insert into database\n",
    "            #     query = f\"\"\"\n",
    "            #     INSERT INTO EmployeeShifts (full_name, shift_start)\n",
    "            #     VALUES ('{name}', '{current_time}');\n",
    "            #     \"\"\"\n",
    "            #     db.run(query)  # Run the query using SQLAlchemy\n",
    "\n",
    "            #     attendance_registered = True\n",
    "            #     print(f\"Attendance registered for {name} at {current_time}\")\n",
    "\n",
    "        # Display results\n",
    "        top, right, bottom, left = face_location\n",
    "        color = (0, 0, 255) if name == \"Unknown\" else (0, 255, 0)\n",
    "        cv2.rectangle(rgb_frame, (left, top), (right, bottom), color, 2)\n",
    "\n",
    "        # Display name\n",
    "        font_scale = 0.75\n",
    "        thickness = 2\n",
    "        cv2.putText(rgb_frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)\n",
    "\n",
    "    # Show video feed\n",
    "    cv2.imshow(\"Face Recognition\", rgb_frame)\n",
    "\n",
    "    # Check if 5 seconds have elapsed or 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import face_recognition\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local():\n",
    "    engine = create_engine(f\"mysql+mysqldb://root:password@localhost/attendance\")\n",
    "    return engine\n",
    "\n",
    "\n",
    "\n",
    "_db = None\n",
    "\n",
    "\n",
    "def connect_db():\n",
    "    \n",
    "    global _db\n",
    "\n",
    "    engine = local()\n",
    "    _db = SQLDatabase(engine=engine)\n",
    "    _db._sample_rows_in_table_info = 0\n",
    "    return _db\n",
    "\n",
    "\n",
    "db= connect_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load face encodings\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_encoding_dir/avg_face_encodings.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 11\u001b[0m     known_faces \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPress \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to quit or wait 5 seconds for automatic attendance.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import face_recognition\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Load face encodings\n",
    "with open(\"avg_encoding_dir/avg_face_encodings.pkl\", \"rb\") as f:\n",
    "    known_faces = pickle.load(f)\n",
    "\n",
    "print(\"Press 'q' to quit or wait 5 seconds for automatic attendance.\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "start_time = time.time()\n",
    "registered_names = set()  # Keep track of registered names during the session\n",
    "\n",
    "while True:\n",
    "    # Capture frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Convert frame to RGB for face recognition\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "    for (face_location, face_encoding) in zip(face_locations, face_encodings):\n",
    "        matches = face_recognition.compare_faces(list(known_faces.values()), face_encoding, tolerance=0.6)\n",
    "        \n",
    "        name = \"Unknown\"\n",
    "\n",
    "        if True in matches:\n",
    "            first_match_index = matches.index(True)\n",
    "            name = list(known_faces.keys())[first_match_index]\n",
    "\n",
    "            # If a known person is detected and their attendance has not been registered\n",
    "            if name not in registered_names:\n",
    "                # Get current timestamp\n",
    "                current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                \n",
    "                # Insert attendance into the database\n",
    "                query = f\"\"\"\n",
    "                    INSERT INTO Attendance (student_id, class_id, session_timestamp, is_present)\n",
    "                    VALUES (\n",
    "                        (SELECT student_id FROM Students WHERE full_name = '{name}' LIMIT 1),\n",
    "                        (SELECT class_id FROM Students WHERE full_name = '{name}' LIMIT 1),\n",
    "                        '{current_time}',\n",
    "                        TRUE\n",
    "                    );\n",
    "                \"\"\"\n",
    "                db.run(query)  # Run the query using the provided db connection\n",
    "\n",
    "                registered_names.add(name)  # Mark this name as registered\n",
    "                print(f\"Attendance registered for {name} at {current_time}\")\n",
    "\n",
    "        # Display results\n",
    "        top, right, bottom, left = face_location\n",
    "        color = (0, 0, 255) if name == \"Unknown\" else (0, 255, 0)\n",
    "        cv2.rectangle(rgb_frame, (left, top), (right, bottom), color, 2)\n",
    "\n",
    "        # Display name\n",
    "        font_scale = 0.75\n",
    "        thickness = 2\n",
    "        cv2.putText(rgb_frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)\n",
    "\n",
    "    # Show video feed\n",
    "    cv2.imshow(\"Face Recognition\", rgb_frame)\n",
    "\n",
    "    # Check if 5 seconds have elapsed or 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q') or (time.time() - start_time > 5):\n",
    "        image_filename = f\"Captured_photos/{name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg\"\n",
    "        cv2.imwrite(image_filename, frame)\n",
    "        break\n",
    "\n",
    "# Release the camera and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
